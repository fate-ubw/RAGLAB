use_seed: True
seed: 633
num_gpu: 1
# eval config
algorithm_name: naive_rag
task: ''
# llm config
llm_mode: HF_Model
llm_path: ./model/Llama3-8B-Instruct-baseline
quantization: None
use_vllm: True
temperature: 0.0
top_p: 1.0
generation_stop: ''
generate_maxlength: 300
# retrieval config
realtime_retrieval: True
retrieval_name: colbert_api
# max length should bigger than the length of input_ids
n_docs: 10
passages_max_length: -1